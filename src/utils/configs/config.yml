# configurables and env

llm:
  together_api_key: ${TOGETHER_API_KEY}
  model: "deepseek-ai/DeepSeek-V3"
  summarize_llm:
    max_tokens: 500
    temperature: 0.3
  test_llm:
    max_tokens: 600
    temperature: 0.4
  orchestrator_llm:
    max_tokens: 100
    temperature: 0.4

